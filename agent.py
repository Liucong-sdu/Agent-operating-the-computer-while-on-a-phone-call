# agent.py (V3 - å·¥å…·æƒé™æ§åˆ¶æœ€ç»ˆç‰ˆ)

import threading
import queue
import time
import io
import wave
import openai
import json
import uuid

import config
from audio_handler import AudioHandler
from llm_handler import LLMHandler
from tts_handler import TTSHandler
from computer_interface import send_goal_to_computer_agent, send_info_to_computer_agent

class VoiceAgent:
    def __init__(self):
        self.large_llm_client = openai.OpenAI(api_key=config.OPENAI_API_KEY, base_url=config.OPENAI_BASE_URL)
        self.small_llm_client = openai.OpenAI(api_key="ollama", base_url=config.OLLAMA_BASE_URL)
        
        self.interrupt_event = threading.Event()
        self.stop_event = threading.Event()
        self.user_speech_queue = queue.Queue()
        
        self.conversation_history = [{"role": "system", "content": config.SYSTEM_PROMPT}]
        self.current_task_id: str | None = None
        self.thinking_lock = threading.RLock()
        
        self.tools = [
            {"type": "function", "function": {"name": "send_goal_to_computer_agent", "description": "å‘ç”µè„‘Agentå‘é€ä¸€ä¸ªå…¨æ–°çš„ã€é«˜çº§åˆ«çš„ä»»åŠ¡ç›®æ ‡ã€‚", "parameters": {"type": "object", "properties": { "goal_description": { "type": "string", "description": "å¯¹ç”¨æˆ·ç›®æ ‡çš„æ¸…æ™°æè¿°ã€‚"}}, "required": ["goal_description"]}}},
            {"type": "function", "function": {"name": "send_info_to_computer_agent", "description": "å½“ç”¨æˆ·æä¾›ä¸€ä¸ªæˆ–å¤šä¸ªå…·ä½“ä¿¡æ¯ç‚¹æ—¶ï¼Œç”¨æ­¤å·¥å…·å°†å®ƒä»¬æ‰“åŒ…å›å¤ç»™ç”µè„‘Agentã€‚", "parameters": {"type": "object", "properties": { "info_list": { "type": "array", "description": "ä¸€ä¸ªåŒ…å«ç”¨æˆ·ä¿¡æ¯å¯¹è±¡çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå¯¹è±¡éƒ½åº”åŒ…å«'field_name'å’Œ'user_info'ã€‚", "items": { "type": "object", "properties": { "field_name": { "type": "string", "description": "å­—æ®µåï¼Œä¾‹å¦‚'å§“å'ã€‚"}, "user_info": { "type": "string", "description": "ç”¨æˆ·æä¾›çš„ã€ç»è¿‡ä¸¥æ ¼æ¸…æ´—å’Œæ ¼å¼åŒ–çš„å…·ä½“ä¿¡æ¯ï¼ˆä¾‹å¦‚ï¼Œå°†'äºŒåå²'è½¬ä¸º'20'ï¼‰ã€‚"}}, "required": ["field_name", "user_info"]}}}, "required": ["info_list"]}}}
        ]
        
        self.audio_handler = AudioHandler(on_speech_start=self.on_speech_start, on_speech_end=self.on_speech_end)
        self.llm_handler = LLMHandler(self.large_llm_client)
        self.tts_handler = TTSHandler(self.large_llm_client)

        self.main_thread = threading.Thread(target=self._main_loop, daemon=True)
        self.computer_message_watcher_thread = threading.Thread(target=self._computer_message_watcher, daemon=True)
    
    def _execute_tool_call(self, tool_call):
        tool_name = tool_call.function.name
        tool_args = json.loads(tool_call.function.arguments)
        
        if self.current_task_id is None:
            self.current_task_id = str(uuid.uuid4())

        if tool_name == "send_goal_to_computer_agent":
            goal = tool_args.get("goal_description")
            print(f"ğŸ› ï¸ ç”µè¯Agent: æ´¾å‘æ–°ç›®æ ‡ -> '{goal}' (ID: {self.current_task_id})")
            return send_goal_to_computer_agent(self.current_task_id, goal)
        
        elif tool_name == "send_info_to_computer_agent":
            info_list = tool_args.get("info_list", [])
            print(f"ğŸ› ï¸ ç”µè¯Agent: æ´¾å‘ä¿¡æ¯åŒ… -> {info_list} (ID: {self.current_task_id})")
            return send_info_to_computer_agent(self.current_task_id, info_list)
            
        return f"æœªçŸ¥å·¥å…·: {tool_name}"

    def on_speech_start(self):
        if self.tts_handler.is_speaking():
            print("ğŸ¤ ç”¨æˆ·å¼€å§‹è¯´è¯ï¼Œæ¸…ç©ºAIè¯­éŸ³é˜Ÿåˆ—å¹¶æ‰“æ–­...")
            self.interrupt_event.set()
            self.tts_handler.stop_current_playback()
            self.tts_handler.clear_queue()
        
    def on_speech_end(self, audio_data):
        self.user_speech_queue.put(audio_data)
    
    def _is_valid_interrupt(self, text: str) -> bool:
        try:
            print(f"ğŸ•µï¸  å®‰æ£€å‘˜(å°æ¨¡å‹): æ­£åœ¨åˆ†ææ‰“æ–­æ–‡æœ¬çš„æœ‰æ•ˆæ€§...")
            prompt = config.INTERRUPT_PROMPT.format(text=text)
            response = self.small_llm_client.chat.completions.create(
                model=config.SMALL_LLM_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10,
                timeout=3
            )
            decision = response.choices[0].message.content.strip().lower()
            if "interrupt" in decision:
                print(f"âœ… å®‰æ£€å‘˜(å°æ¨¡å‹): åˆ¤æ–­ä¸ºæœ‰æ•ˆæ‰“æ–­ã€‚å†…å®¹: '{text}'")
                return True
            else:
                print(f"âŒ å®‰æ£€å‘˜(å°æ¨¡å‹): åˆ¤æ–­ä¸ºæ— æ•ˆæ‰“æ–­(å™ªéŸ³/å£å¤´ç¦…)ï¼Œå·²å¿½ç•¥ã€‚å†…å®¹: '{text}'")
                return False
        except Exception as e:
            print(f"âš ï¸ å®‰æ£€å‘˜(å°æ¨¡å‹): åˆ¤æ–­æ—¶å‡ºé”™ ({e})ï¼Œä¸ºå®‰å…¨èµ·è§ï¼Œé»˜è®¤è§†ä¸ºæœ‰æ•ˆæ‰“æ–­ã€‚")
            return True

    def _main_loop(self):
        while not self.stop_event.is_set():
            try:
                audio_data = self.user_speech_queue.get(block=True, timeout=1)
                
                with self.thinking_lock:
                    user_text = ""
                    try:
                        user_text = self._transcribe(audio_data)
                        print(f"ğŸ¤« [ä¸»å¾ªç¯-è½¬å½•å®Œæˆ]: \"{user_text}\"")
                    except Exception as e:
                        print(f"âŒ [ä¸»å¾ªç¯]: éŸ³é¢‘è½¬å½•å¤±è´¥: {e}ï¼Œå·²å¿½ç•¥æœ¬æ¬¡è¾“å…¥ã€‚")
                        continue 

                    if not user_text or not user_text.strip():
                        continue 
                    
                    was_interrupted = self.interrupt_event.is_set()
                    if was_interrupted:
                        if not self._is_valid_interrupt(user_text):
                            self.interrupt_event.clear()
                            continue

                    print(f"ğŸ’¬ [ä¸»å¾ªç¯-ç¡®è®¤æŒ‡ä»¤]: ç”¨æˆ·è¯´: '{user_text}'")
                    self.conversation_history.append({"role": "user", "content": user_text})
                    self._trigger_large_llm(allow_tool_calls=True)

            except queue.Empty:
                continue

    def _computer_message_watcher(self):
        from shared_queues import q2_queue
        while not self.stop_event.is_set():
            try:
                message = q2_queue.get(timeout=0.5)
                print(f"ğŸ“¬ ç”µè¯Agent: æ”¶åˆ°ç”µè„‘å›æ‰§: {message['payload']}")
                
                with self.thinking_lock:
                    print("ğŸ“¬ ç”µè¯Agent: å·²è·å¾—æ€è€ƒé”ï¼Œæ­£åœ¨å¤„ç†ç”µè„‘å›æ‰§...")
                    self.interrupt_event.set() 
                    self.tts_handler.stop_current_playback()
                    self.tts_handler.clear_queue()
                    
                    self.conversation_history.append({"role": "user", "content": f"[FROM_COMPUTER_AGENT] {message['payload']}"})
                    # ã€æ ¸å¿ƒæ”¹é€ ã€‘å¤„ç†ç”µè„‘å›æ‰§æ—¶ï¼Œåªå…è®¸LLMè¯´è¯ï¼Œä¸å…è®¸å†è°ƒç”¨å·¥å…·
                    self._trigger_large_llm(allow_tool_calls=False)

            except queue.Empty:
                continue

    def _transcribe(self, audio_data):
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, "wb") as wf:
            wf.setnchannels(config.AUDIO_CHANNELS)
            wf.setsampwidth(2)
            wf.setframerate(config.AUDIO_SAMPLING_RATE)
            wf.writeframes(audio_data)
        wav_buffer.seek(0)
        wav_buffer.name = "audio.wav"
        transcription = self.large_llm_client.audio.transcriptions.create(model=config.STT_MODEL, file=wav_buffer)
        return transcription.text

    def _trigger_large_llm(self, allow_tool_calls: bool = True): # <--- ã€æ”¹é€ ã€‘å¢åŠ æƒé™å‚æ•°
        try:
            self.tts_handler.clear_queue()
            self.interrupt_event.clear()
            
            # ã€æ”¹é€ ã€‘æ ¹æ®æƒé™å‚æ•°å†³å®šæ˜¯å¦ç»™LLMå·¥å…·
            active_tools = self.tools if allow_tool_calls else None
            response_stream = self.llm_handler.get_llm_response_stream(history=self.conversation_history, tools=active_tools)

            full_response_text = ""
            tool_calls = []
            
            for chunk_type, content in response_stream:
                if self.interrupt_event.is_set():
                    print("ğŸ§  LLMå¤„ç†å™¨: æ£€æµ‹åˆ°æ‰“æ–­äº‹ä»¶ï¼Œç»ˆæ­¢ç”Ÿæˆã€‚")
                    break
                if chunk_type == "text":
                    self.tts_handler.play_audio_stream(content, self.interrupt_event)
                    full_response_text += content
                elif chunk_type == "tool_call":
                    tool_calls.append(content)
            
            if tool_calls and not self.interrupt_event.is_set():
                tool_call = tool_calls[0]
                result = self._execute_tool_call(tool_call)
                assistant_message = {"role": "assistant", "content": full_response_text or None}
                if tool_calls:
                   assistant_message["tool_calls"] = [tc.model_dump() for tc in tool_calls]
                
                self.conversation_history.append(assistant_message)
                self.conversation_history.append({"role": "tool", "tool_call_id": tool_call.id, "name": tool_call.function.name, "content": result})
                
                # ã€æ ¸å¿ƒæ”¹é€ ã€‘åœ¨å¤„ç†å®Œå·¥å…·ç»“æœåï¼Œåªå…è®¸LLMè¯´è¯ï¼Œä¸å…è®¸å†è¿ç»­è°ƒç”¨å·¥å…·
                self._trigger_large_llm(allow_tool_calls=False)
                return

            if not self.interrupt_event.is_set():
                self.tts_handler.wait_for_completion()

            if not self.interrupt_event.is_set() and full_response_text.strip():
                self.conversation_history.append({"role": "assistant", "content": full_response_text.strip()})
        finally:
            self.interrupt_event.clear()

    def start(self):
        print("ğŸš€ Voice Agent: æ­£åœ¨å¯åŠ¨...")
        self.audio_handler.start()
        self.main_thread.start()
        self.computer_message_watcher_thread.start()

    def stop(self):
        print("ğŸ›‘ Voice Agent: æ­£åœ¨åœæ­¢...")
        self.stop_event.set()
        self.audio_handler.stop()
        self.tts_handler.cleanup()
        if self.main_thread.is_alive():
            self.main_thread.join()
        if self.computer_message_watcher_thread.is_alive():
            self.computer_message_watcher_thread.join()
        print("ğŸ›‘ Voice Agent: å·²å®Œå…¨åœæ­¢ã€‚")