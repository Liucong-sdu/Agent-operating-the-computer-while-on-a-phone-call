# agent.py (æœ€ç»ˆå®Œç¾ç‰ˆ)

import threading
import queue
import time
import io
import wave
import openai
import json

import config
from audio_handler import AudioHandler
from llm_handler import LLMHandler
from tts_handler import TTSHandler
from computer_agent_interface import q2_queue, send_message_to_computer_agent

class VoiceAgent:
    def __init__(self):
        self.large_llm_client = openai.OpenAI(api_key=config.OPENAI_API_KEY)
        self.small_llm_client = openai.OpenAI(api_key="ollama", base_url=config.OLLAMA_BASE_URL)

        self.interrupt_event = threading.Event()
        self.stop_event = threading.Event()
        
        self.decision_queue = queue.Queue(maxsize=1)

        self.user_speech_queue = queue.Queue()
        self.conversation_history = [{"role": "system", "content": config.SYSTEM_PROMPT}]
        
        self.tools = [
            {
                "type": "function",
                "function": {
                    "name": "send_message_to_computer_agent",
                    "description": "å‘æ“ä½œæµè§ˆå™¨çš„ç”µè„‘Agentå‘é€æ¶ˆæ¯æˆ–æŒ‡ä»¤ã€‚",
                    "parameters": {
                        "type": "object",
                        "properties": { "message": { "type": "string", "description": "è¦å‘é€ç»™ç”µè„‘Agentçš„ä¿¡æ¯æˆ–æŒ‡ä»¤ã€‚"}},
                        "required": ["message"],
                    },
                },
            }
        ]
        
        self.audio_handler = AudioHandler(
            on_speech_start=self.on_speech_start, 
            on_speech_end=self.on_speech_end
        )
        self.llm_handler = LLMHandler(self.large_llm_client)
        self.tts_handler = TTSHandler(self.large_llm_client)

        self.main_thread = threading.Thread(target=self._main_loop)
        self.queue_2_watcher_thread = threading.Thread(target=self._queue_2_watcher)

    def _is_system_busy(self):
        return self.llm_handler.is_active() or self.tts_handler.is_speaking()

    def on_speech_start(self):
        print("ğŸ¤ éŸ³é¢‘å¤„ç†å™¨: æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹ï¼Œå¯åŠ¨å¹¶è¡Œå†³ç­–...")
        threading.Thread(target=self._fast_decision_thread).start()

    def on_speech_end(self, audio_data):
        print("ğŸ¤ [è·¯å¾„B]: ç”¨æˆ·å·²è¯´å®Œï¼Œç­‰å¾…è·¯å¾„Açš„æœ€ç»ˆå†³ç­–...")
        try:
            decision = self.decision_queue.get(timeout=10.0)
            print(f"ğŸ¤ [è·¯å¾„B]: æ”¶åˆ°å†³ç­– -> '{decision}'")
            
            if decision == "process":
                duration = len(audio_data) / (config.AUDIO_SAMPLING_RATE * 2)
                print(f"ğŸ¤ [è·¯å¾„B]: å†³å®šå¤„ç†è¯¥éŸ³é¢‘ ({duration:.2f}s)ï¼Œæ”¾å…¥ä¸»é˜Ÿåˆ—ã€‚")
                self.user_speech_queue.put(audio_data)
            else: # "ignore"
                print("ğŸ¤« [è·¯å¾„B]: å†³å®šå¿½ç•¥æœ¬æ¬¡å½•éŸ³ï¼ŒAIæ’­æŠ¥ä¸å—å½±å“ã€‚")
        except queue.Empty:
            print("ğŸ¤ [è·¯å¾„B]: ç­‰å¾…å†³ç­–è¶…æ—¶ï¼Œä¸ºå®‰å…¨èµ·è§ï¼Œé»˜è®¤å¤„ç†è¯¥éŸ³é¢‘ã€‚")
            self.user_speech_queue.put(audio_data)
        finally:
            while not self.decision_queue.empty():
                try: self.decision_queue.get_nowait()
                except queue.Empty: break

    def _fast_decision_thread(self):
        decision = "process" 
        try:
            time.sleep(config.FAST_CHECK_DURATION_S)
            audio_snapshot = b''.join(list(self.audio_handler.speech_buffer))

            if len(audio_snapshot) < 2048:
                print("âš¡ï¸ [è·¯å¾„A]: éŸ³é¢‘å¿«ç…§è¿‡çŸ­ï¼Œåˆ¤å®šä¸º->å¿½ç•¥ã€‚")
                decision = "ignore"
                return

            text = self._transcribe(audio_snapshot)
            if not text.strip():
                print("âš¡ï¸ [è·¯å¾„A]: è½¬å½•ä¸ºç©ºï¼Œåˆ¤å®šä¸º->å¿½ç•¥ã€‚")
                decision = "ignore"
                return

            print(f"âš¡ï¸ [è·¯å¾„A]: å°æ¨¡å‹åˆ†æå¿«ç…§æ–‡æœ¬: '{text}'")
            
            prompt = config.INTERRUPT_PROMPT.format(text=text)
            response = self.small_llm_client.chat.completions.create(
                model=config.SMALL_LLM_MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=10,
                timeout=8,
            )
            model_decision = response.choices[0].message.content.strip().lower()
            print(f"âš¡ï¸ [è·¯å¾„A]: å°æ¨¡å‹å†³å®š -> {model_decision}")

            if model_decision == "interrupt":
                print("â€¼ï¸ [è·¯å¾„A]: å†³å®š->æ‰“æ–­å¹¶å¤„ç†ï¼")
                self.interrupt_event.set()
                decision = "process"
            else: # disinterrupt
                print("ğŸ¤« [è·¯å¾„A]: å†³å®š->ä¸æ‰“æ–­å¹¶å¿½ç•¥ã€‚")
                self.interrupt_event.clear()
                decision = "ignore"

        except Exception as e:
             print(f"âš¡ï¸ [è·¯å¾„A]: å¿«é€Ÿå†³ç­–æ—¶å‡ºé”™: {e}ã€‚é»˜è®¤å¤„ç†ã€‚")
             decision = "process"
             self.interrupt_event.set()
        finally:
            print(f"âš¡ï¸ [è·¯å¾„A]: å†³ç­–æµç¨‹ç»“æŸï¼Œå°†æœ€ç»ˆå†³ç­– '{decision}' æ”¾å…¥é˜Ÿåˆ—ã€‚")
            self.decision_queue.put(decision)

    def _apply_input_guardrails(self, user_text):
        if "æ£ä¹±" in user_text:
            print("ğŸš§ [æŠ¤æ ]: æ£€æµ‹åˆ°æ— å…³è¾“å…¥ï¼Œè§¦å‘æŠ¤æ ã€‚")
            self.interrupt_event.clear()
            self.tts_handler.play_audio_stream("è¯·æˆ‘ä»¬ä¸“æ³¨äºå½“å‰ä»»åŠ¡ã€‚", self.interrupt_event)
            self.tts_handler.wait_for_completion()
            return True
        return False

    def _main_loop(self):
        while not self.stop_event.is_set():
            try:
                audio_data = self.user_speech_queue.get(timeout=1)
                print("ğŸ’¬ [ä¸»å¾ªç¯]: æ­£åœ¨å¤„ç†é˜Ÿåˆ—ä¸­çš„æ–°éŸ³é¢‘...")
                user_text = self._transcribe(audio_data)
                print(f"ğŸ’¬ [ä¸»å¾ªç¯]: ç”¨æˆ·è¯´: '{user_text}'")
                if self._apply_input_guardrails(user_text):
                    continue
                self.conversation_history.append({"role": "user", "content": user_text})
                self._trigger_large_llm()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"ğŸ’¬ [ä¸»å¾ªç¯]: å‘ç”Ÿé”™è¯¯: {e}")

    def _queue_2_watcher(self):
        while not self.stop_event.is_set():
            try:
                if not self._is_system_busy() and not q2_queue.is_empty():
                    messages = q2_queue.get()
                    for message in messages:
                        print(f"ğŸ“¦ [æ¶ˆæ¯ç›‘å¬]: ä»ç”µè„‘Agentå¤„è·å¾—æ¶ˆæ¯: '{message}'")
                        self.conversation_history.append({"role": "user", "content": f"[FROM_COMPUTER_AGENT] {message}"})
                    self._trigger_large_llm()
                else:
                    time.sleep(0.5)
            except Exception as e:
                print(f"ğŸ“¦ [æ¶ˆæ¯ç›‘å¬]: å‘ç”Ÿé”™è¯¯: {e}")

    def _transcribe(self, audio_data):
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, "wb") as wf:
            wf.setnchannels(config.AUDIO_CHANNELS)
            wf.setsampwidth(2)
            wf.setframerate(config.AUDIO_SAMPLING_RATE)
            wf.writeframes(audio_data)
        wav_buffer.seek(0)
        wav_buffer.name = "audio.wav"
        transcription = self.large_llm_client.audio.transcriptions.create(model=config.STT_MODEL, file=wav_buffer)
        return transcription.text

    def _trigger_large_llm(self):
        """è§¦å‘å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆå“åº”ã€‚"""
        try:
            ## -------------------- æœ€ç»ˆçš„ã€å…³é”®çš„ä¿®å¤ -------------------- ##
            # åœ¨ç”Ÿæˆä»»ä½•æ–°å›å¤ä¹‹å‰ï¼Œæ¸…ç©ºTTSçš„å¾…åŠåˆ—è¡¨
            self.tts_handler.clear_queue()
            ## -------------------- ä¿®å¤ç»“æŸ -------------------- ##

            self.interrupt_event.clear()
            
            response_stream = self.llm_handler.get_llm_response_stream(
                history=self.conversation_history,
                tools=self.tools
            )
            full_response_text = ""
            tool_call_in_progress = None
            for chunk_type, content in response_stream:
                if self.interrupt_event.is_set():
                    print("ğŸ¤– æ™ºèƒ½ä½“: å¤§æ¨¡å‹å“åº”æµè¢«ä¸­æ–­ï¼")
                    break
                if chunk_type == "text":
                    self.tts_handler.play_audio_stream(content, self.interrupt_event)
                    full_response_text += content
                elif chunk_type == "tool_call":
                    tool_call_in_progress = content
                    break
            if tool_call_in_progress and not self.interrupt_event.is_set():
                tool_name = tool_call_in_progress.function.name
                tool_args = json.loads(tool_call_in_progress.function.arguments)
                print(f"ğŸ› ï¸ æ™ºèƒ½ä½“: è°ƒç”¨å·¥å…· '{tool_name}'ï¼Œå‚æ•°: {tool_args}")
                result = send_message_to_computer_agent(message=tool_args.get("message"))
                self.conversation_history.append({"role": "assistant", "content": None, "tool_calls": [tool_call_in_progress.model_dump()]})
                self.conversation_history.append({"role": "tool", "tool_call_id": tool_call_in_progress.id, "name": tool_name, "content": result})
                self._trigger_large_llm()
                return
            self.tts_handler.wait_for_completion()
            if not self.interrupt_event.is_set() and full_response_text.strip():
                self.conversation_history.append({"role": "assistant", "content": full_response_text.strip()})
        finally:
            self.interrupt_event.clear()

    def start(self):
        print("ğŸš€ æ™ºèƒ½ä½“: æ­£åœ¨å¯åŠ¨...")
        self.audio_handler.start()
        self.main_thread.start()
        self.queue_2_watcher_thread.start()
        self.conversation_history.append({"role": "user", "content": "ä½ å¥½ï¼Œè¯·å¼€å§‹è¿›è¡Œè‡ªæˆ‘ä»‹ç»å’Œä»»åŠ¡è¯´æ˜ã€‚"})
        self._trigger_large_llm()

    def stop(self):
        print("ğŸ›‘ æ™ºèƒ½ä½“: æ­£åœ¨åœæ­¢...")
        self.stop_event.set()
        self.audio_handler.stop()
        self.tts_handler.cleanup()
        if self.main_thread.is_alive():
            self.main_thread.join()
        if self.queue_2_watcher_thread.is_alive():
            self.queue_2_watcher_thread.join()
        print("ğŸ›‘ æ™ºèƒ½ä½“: å·²å®Œå…¨åœæ­¢ã€‚")